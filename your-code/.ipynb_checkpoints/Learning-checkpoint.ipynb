{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with RSS Feeds\n",
    "\n",
    "\n",
    "Lesson Goals\n",
    "\n",
    "    Learn about the feedparser library\n",
    "    Use feedparser to parse RSS feeds\n",
    "    Explore the components of parsed RSS feeds\n",
    "    Convert results into data frames and conduct analysis\n",
    "\n",
    "Introduction\n",
    "\n",
    "In the previous lesson, we learned how to use Python to extract structured information from web APIs. In this lesson, we are going to take a look at another source of structured web content called RSS. RSS stands for Rich Site Summary or Really Simple Syndication, and it is a type of web feed which allows users and applications to access updates to online content in a standardized, computer-readable format (typically XML).\n",
    "\n",
    "Python has an excellent library called feedparser that is very useful for reading and parsing RSS feeds. We are going to be using this library throughout the lesson, so let's make sure it is installed and imported.\n",
    "\n",
    "$ pip install feedparser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6076 sha256=e65c42829778b97ccfaada0b2f7b72f940bc837fc484ee0918ccefc9f92700f4\n",
      "  Stored in directory: c:\\users\\sandr\\appdata\\local\\pip\\cache\\wheels\\bb\\cb\\26\\83c0b63161dc478ded6db8d83a148d32b6cce8606043c2023b\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.10 sgmllib3k-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n",
    "\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS Feed Versions Formats\n",
    "\n",
    "Due to the way web feeds evolved, there are various versions of RSS (0.9X, 1.0, 2.0, etc.) as well as alternate forms of feeds (Atom, CDF, etc.). We would have to worry about slight differences in formats if we were going to parse the feeds manually, but feedparser is able to handle all of them, so that is one less thing we need to worry about.\n",
    "\n",
    "\n",
    "# Parsing RSS Feeds\n",
    "\n",
    "To parse an RSS feed with feedparser, you just need to call its parse method and pass it a URL. Let's take a look at an example using the RSS feed for the tech subreddit category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = feedparser.parse('https://www.reddit.com/r/tech.rss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the results, we will see a nested dictionary structure that contains a lot of information and looks something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': [{'term': 'tech', 'scheme': None, 'label': 'r/tech'}], 'updated': '2022-11-22T02:59:22+00:00', 'updated_parsed': time.struct_time(tm_year=2022, tm_mon=11, tm_mday=22, tm_hour=2, tm_min=59, tm_sec=22, tm_wday=1, tm_yday=326, tm_isdst=0), 'icon': 'https://www.redditstatic.com/icon.png/', 'id': 'https://www.reddit.com/r/tech.rss', 'guidislink': True, 'link': 'https://www.reddit.com/r/tech', 'links': [{'rel': 'self', 'href': 'https://www.reddit.com/r/tech.rss', 'type': 'application/atom+xml'}, {'rel': 'alternate', 'href': 'https://www.reddit.com/r/tech', 'type': 'text/html'}], 'logo': 'https://f.thumbs.redditmedia.com/kI7eGVG6kaObGTdM.png', 'subtitle': 'The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.', 'subtitle_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/tech.rss', 'value': 'The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.'}, 'title': '/r/tech: Technological innovations and changes.', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/tech.rss', 'value': '/r/tech: Technological innovations and changes.'}}\n"
     ]
    }
   ],
   "source": [
    "print(reddit['feed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great because we can now use what we learned earlier in the program about working with data structures to explore and extract the information we need from this.\n",
    "\n",
    "\n",
    "\n",
    "# Exploring the Parsed Feed\n",
    "\n",
    "Let's take a look at the first level of dictionary keys from the results and see what each of them looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bozo', 'entries', 'feed', 'headers', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the different components of the RSS feed, and each of them is going to contain information about something more specific. For example, feed is going to contain information about this Reddit RSS feed, entries is going to contain information about the specific entries in the feed, etc.\n",
    "\n",
    "Since the feed component is now structured as just a dictionary inside the larger dictionary, we can view its keys to get a sense of what type of information is available to us within the feed dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tags', 'updated', 'updated_parsed', 'icon', 'id', 'guidislink', 'link', 'links', 'logo', 'subtitle', 'subtitle_detail', 'title', 'title_detail'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that we would be able to extract any tags for the feed, when the feed was updated, and the icon image for the feed as well as the feed title, subtitle, and various other pieces of information about it. You can see what each of those looks like by calling each component from reddit.feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'term': 'tech', 'scheme': None, 'label': 'r/tech'}]\n",
      "\n",
      "https://www.redditstatic.com/icon.png/\n",
      "\n",
      "/r/tech: Technological innovations and changes.\n",
      "\n",
      "The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.\n"
     ]
    }
   ],
   "source": [
    "print (reddit.feed.tags)\n",
    "print ('')\n",
    "print (reddit.feed.icon)\n",
    "print ('')\n",
    "print (reddit.feed.title)\n",
    "print ('')\n",
    "print (reddit.feed.subtitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, but the most interesting part of the feed is probably going to be the entries. We can access them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': [{'name': '/u/Zee2A',\n",
       "   'href': 'https://www.reddit.com/user/Zee2A'}],\n",
       " 'author_detail': {'name': '/u/Zee2A',\n",
       "  'href': 'https://www.reddit.com/user/Zee2A'},\n",
       " 'href': 'https://www.reddit.com/user/Zee2A',\n",
       " 'author': '/u/Zee2A',\n",
       " 'tags': [{'term': 'tech', 'scheme': None, 'label': 'r/tech'}],\n",
       " 'content': [{'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'https://www.reddit.com/r/tech.rss',\n",
       "   'value': '&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zee2A\"> /u/Zee2A </a> <br /> <span><a href=\"https://www.cbsnews.com/philadelphia/news/lung-cancer-survival-rates-improving-report-says/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/tech/comments/z115ai/new_robotic_technology_helping_to_find_treat_lung/\">[comments]</a></span>'}],\n",
       " 'summary': '&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Zee2A\"> /u/Zee2A </a> <br /> <span><a href=\"https://www.cbsnews.com/philadelphia/news/lung-cancer-survival-rates-improving-report-says/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/tech/comments/z115ai/new_robotic_technology_helping_to_find_treat_lung/\">[comments]</a></span>',\n",
       " 'id': 'https://www.reddit.com/r/t3_z115ai',\n",
       " 'guidislink': True,\n",
       " 'link': 'https://www.reddit.com/r/tech/comments/z115ai/new_robotic_technology_helping_to_find_treat_lung/',\n",
       " 'links': [{'href': 'https://www.reddit.com/r/tech/comments/z115ai/new_robotic_technology_helping_to_find_treat_lung/',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'}],\n",
       " 'updated': '2022-11-21T15:03:42+00:00',\n",
       " 'updated_parsed': time.struct_time(tm_year=2022, tm_mon=11, tm_mday=21, tm_hour=15, tm_min=3, tm_sec=42, tm_wday=0, tm_yday=325, tm_isdst=0),\n",
       " 'published': '2022-11-21T15:03:42+00:00',\n",
       " 'published_parsed': time.struct_time(tm_year=2022, tm_mon=11, tm_mday=21, tm_hour=15, tm_min=3, tm_sec=42, tm_wday=0, tm_yday=325, tm_isdst=0),\n",
       " 'title': 'New robotic technology helping to find, treat lung cancer.',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'https://www.reddit.com/r/tech.rss',\n",
       "  'value': 'New robotic technology helping to find, treat lung cancer.'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data structure within this seems to be a list where each entry is an element that contains a dictionary with the information for each entry. We can access the individual entries via indexing and then we can look at the keys available for the entry by calling the keys() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['authors', 'author_detail', 'href', 'author', 'tags', 'content', 'summary', 'id', 'guidislink', 'link', 'links', 'updated', 'updated_parsed', 'published', 'published_parsed', 'title', 'title_detail'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to obtain a particular piece of data for an entry, we could just index that entry and then call the key for the information we wanted. For example, if we wanted to get the title of the third entry, we would obtain it as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA Plans For Humans To Live On The Moon ‘This Decade,’ Official Tells BBC'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[2].title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the titles for all the entries, we could use a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New robotic technology helping to find, treat lung cancer.', 'Researchers build a working camera out of atomically thin semiconductors. Sheet of atoms works similarly to silicon but has some unique properties.', 'NASA Plans For Humans To Live On The Moon ‘This Decade,’ Official Tells BBC', 'Meta rolls out new privacy updates for teens on Instagram and Facebook', 'Humanoid Robots: Sooner Than You Might Think', 'Scientists Have Developed a Wearable Ring That Repels Insects', 'US is increasing pace of hypersonic weapons development to chase China and Russia, senior admiral says | CNN Politics', 'The Prius gets a glow-up, but it’s still just a hybrid', 'Intel Says Their Deepfake Detector Has 96% Accuracy', 'FDA approves lab-grown meat for the first time', 'You Could Soon Be Wearing Cow Burps and Farts', 'Mammoth is chasing CRISPR 2.0 with a smaller pair of scissors', 'AI will replace middle management before robots replace hourly workers', 'Mini Wind Turbines For Rooftops: ‘Up to 50% More Power’ and No Spinning Blades', 'How researchers used CRISPR gene editing to send immune cells after cancer', 'How this underwater buoy captures the Ocean\\'s power. A Scottish startup says its prototype wave-energy device produced \"highly encouraging results.\"', \"Scientists got lab-grown human brain cells to play 'Pong'\", 'Photoshop for text', 'Cyber vulnerability in networks used by spacecraft, aircraft and energy generation systems', 'New blue quantum dot technology could lead to more energy-efficient displays', 'Tim Berners-Lee shares his vision of a collaborative web', 'ESA SOLARIS: Wireless Power Beamed Down From Space', 'Tesla opens its EV charging connector design in an effort to encourage automakers to adopt the technology.', 'This Is Life in the Metaverse', 'Amazon’s New Warehouse Robot Could One Day Replace Humans']\n"
     ]
    }
   ],
   "source": [
    "titles = [reddit.entries[i].title for i in range(len(reddit.entries))]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Data From an RSS Feed\n",
    "\n",
    "Thus far, feedparser has helped us obtain data from an RSS feed and structure in a way that makes it easy for us to explore it and extract the information we need. If we wanted to analyze the data further, we could leverage the Pandas library and create a data frame containing the information about entries in the feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>href</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>links</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>summary</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/u/Zee2A</td>\n",
       "      <td>{'name': '/u/Zee2A', 'href': 'https://www.redd...</td>\n",
       "      <td>[{'name': '/u/Zee2A', 'href': 'https://www.red...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/user/Zee2A</td>\n",
       "      <td>https://www.reddit.com/r/t3_z115ai</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/z115ai/...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2022-11-21T15:03:42+00:00</td>\n",
       "      <td>(2022, 11, 21, 15, 3, 42, 0, 325, 0)</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>New robotic technology helping to find, treat ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2022-11-21T15:03:42+00:00</td>\n",
       "      <td>(2022, 11, 21, 15, 3, 42, 0, 325, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>{'name': '/u/Sariel007', 'href': 'https://www....</td>\n",
       "      <td>[{'name': '/u/Sariel007', 'href': 'https://www...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/user/Sariel007</td>\n",
       "      <td>https://www.reddit.com/r/t3_z0kbye</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/z0kbye/...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2022-11-21T00:31:26+00:00</td>\n",
       "      <td>(2022, 11, 21, 0, 31, 26, 0, 325, 0)</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>Researchers build a working camera out of atom...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2022-11-21T00:31:26+00:00</td>\n",
       "      <td>(2022, 11, 21, 0, 31, 26, 0, 325, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/eyefunmar</td>\n",
       "      <td>{'name': '/u/eyefunmar', 'href': 'https://www....</td>\n",
       "      <td>[{'name': '/u/eyefunmar', 'href': 'https://www...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/user/eyefunmar</td>\n",
       "      <td>https://www.reddit.com/r/t3_yzyrql</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/yzyrql/...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2022-11-20T08:15:31+00:00</td>\n",
       "      <td>(2022, 11, 20, 8, 15, 31, 6, 324, 0)</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>NASA Plans For Humans To Live On The Moon ‘Thi...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2022-11-20T08:15:31+00:00</td>\n",
       "      <td>(2022, 11, 20, 8, 15, 31, 6, 324, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/u/MicroSofty88</td>\n",
       "      <td>{'name': '/u/MicroSofty88', 'href': 'https://w...</td>\n",
       "      <td>[{'name': '/u/MicroSofty88', 'href': 'https://...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/user/MicroSofty88</td>\n",
       "      <td>https://www.reddit.com/r/t3_z1488t</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/z1488t/...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2022-11-21T17:11:14+00:00</td>\n",
       "      <td>(2022, 11, 21, 17, 11, 14, 0, 325, 0)</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>Meta rolls out new privacy updates for teens o...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2022-11-21T17:11:14+00:00</td>\n",
       "      <td>(2022, 11, 21, 17, 11, 14, 0, 325, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/u/par695</td>\n",
       "      <td>{'name': '/u/par695', 'href': 'https://www.red...</td>\n",
       "      <td>[{'name': '/u/par695', 'href': 'https://www.re...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/user/par695</td>\n",
       "      <td>https://www.reddit.com/r/t3_z00wws</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/z00wws/...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2022-11-20T10:34:33+00:00</td>\n",
       "      <td>(2022, 11, 20, 10, 34, 33, 6, 324, 0)</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>Humanoid Robots: Sooner Than You Might Think</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2022-11-20T10:34:33+00:00</td>\n",
       "      <td>(2022, 11, 20, 10, 34, 33, 6, 324, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                      author_detail  \\\n",
       "0         /u/Zee2A  {'name': '/u/Zee2A', 'href': 'https://www.redd...   \n",
       "1     /u/Sariel007  {'name': '/u/Sariel007', 'href': 'https://www....   \n",
       "2     /u/eyefunmar  {'name': '/u/eyefunmar', 'href': 'https://www....   \n",
       "3  /u/MicroSofty88  {'name': '/u/MicroSofty88', 'href': 'https://w...   \n",
       "4        /u/par695  {'name': '/u/par695', 'href': 'https://www.red...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'name': '/u/Zee2A', 'href': 'https://www.red...   \n",
       "1  [{'name': '/u/Sariel007', 'href': 'https://www...   \n",
       "2  [{'name': '/u/eyefunmar', 'href': 'https://www...   \n",
       "3  [{'name': '/u/MicroSofty88', 'href': 'https://...   \n",
       "4  [{'name': '/u/par695', 'href': 'https://www.re...   \n",
       "\n",
       "                                             content  guidislink  \\\n",
       "0  [{'type': 'text/html', 'language': None, 'base...        True   \n",
       "1  [{'type': 'text/html', 'language': None, 'base...        True   \n",
       "2  [{'type': 'text/html', 'language': None, 'base...        True   \n",
       "3  [{'type': 'text/html', 'language': None, 'base...        True   \n",
       "4  [{'type': 'text/html', 'language': None, 'base...        True   \n",
       "\n",
       "                                       href  \\\n",
       "0         https://www.reddit.com/user/Zee2A   \n",
       "1     https://www.reddit.com/user/Sariel007   \n",
       "2     https://www.reddit.com/user/eyefunmar   \n",
       "3  https://www.reddit.com/user/MicroSofty88   \n",
       "4        https://www.reddit.com/user/par695   \n",
       "\n",
       "                                   id  \\\n",
       "0  https://www.reddit.com/r/t3_z115ai   \n",
       "1  https://www.reddit.com/r/t3_z0kbye   \n",
       "2  https://www.reddit.com/r/t3_yzyrql   \n",
       "3  https://www.reddit.com/r/t3_z1488t   \n",
       "4  https://www.reddit.com/r/t3_z00wws   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.reddit.com/r/tech/comments/z115ai/...   \n",
       "1  https://www.reddit.com/r/tech/comments/z0kbye/...   \n",
       "2  https://www.reddit.com/r/tech/comments/yzyrql/...   \n",
       "3  https://www.reddit.com/r/tech/comments/z1488t/...   \n",
       "4  https://www.reddit.com/r/tech/comments/z00wws/...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "1  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "2  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "3  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "4  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "\n",
       "                   published                       published_parsed  \\\n",
       "0  2022-11-21T15:03:42+00:00   (2022, 11, 21, 15, 3, 42, 0, 325, 0)   \n",
       "1  2022-11-21T00:31:26+00:00   (2022, 11, 21, 0, 31, 26, 0, 325, 0)   \n",
       "2  2022-11-20T08:15:31+00:00   (2022, 11, 20, 8, 15, 31, 6, 324, 0)   \n",
       "3  2022-11-21T17:11:14+00:00  (2022, 11, 21, 17, 11, 14, 0, 325, 0)   \n",
       "4  2022-11-20T10:34:33+00:00  (2022, 11, 20, 10, 34, 33, 6, 324, 0)   \n",
       "\n",
       "                                             summary  \\\n",
       "0  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "1  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "2  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "3  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "4  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "1  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "2  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "3  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "4  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "\n",
       "                                               title  \\\n",
       "0  New robotic technology helping to find, treat ...   \n",
       "1  Researchers build a working camera out of atom...   \n",
       "2  NASA Plans For Humans To Live On The Moon ‘Thi...   \n",
       "3  Meta rolls out new privacy updates for teens o...   \n",
       "4       Humanoid Robots: Sooner Than You Might Think   \n",
       "\n",
       "                                        title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                     updated                         updated_parsed  \n",
       "0  2022-11-21T15:03:42+00:00   (2022, 11, 21, 15, 3, 42, 0, 325, 0)  \n",
       "1  2022-11-21T00:31:26+00:00   (2022, 11, 21, 0, 31, 26, 0, 325, 0)  \n",
       "2  2022-11-20T08:15:31+00:00   (2022, 11, 20, 8, 15, 31, 6, 324, 0)  \n",
       "3  2022-11-21T17:11:14+00:00  (2022, 11, 21, 17, 11, 14, 0, 325, 0)  \n",
       "4  2022-11-20T10:34:33+00:00  (2022, 11, 20, 10, 34, 33, 6, 324, 0)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(reddit.entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the information in a data frame, we can use Pandas to perform a variety of aggregations and calculations. For example, suppose we wanted to know which author has posted the most entries. We could do that by aggregating by author, counting the number of entry titles, and then sorting the results in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/u/fagnerbrack</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/u/CEOAerotyneLtd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/u/mrmowfly186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/u/rayhumrib</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/u/postalex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/u/par695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/u/hopputhas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/u/geoxol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/u/eyefunmar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/u/EforieNord</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/u/contentPudding28926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/u/Zee2A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/u/MicroSofty88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/u/Lonely-Salt2070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/Hyperion1144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/u/wag334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author  entries\n",
       "9           /u/fagnerbrack        5\n",
       "5             /u/Sariel007        3\n",
       "0        /u/CEOAerotyneLtd        2\n",
       "12          /u/mrmowfly186        2\n",
       "15            /u/rayhumrib        1\n",
       "14             /u/postalex        1\n",
       "13               /u/par695        1\n",
       "11            /u/hopputhas        1\n",
       "10               /u/geoxol        1\n",
       "8             /u/eyefunmar        1\n",
       "1            /u/EforieNord        1\n",
       "7   /u/contentPudding28926        1\n",
       "6                 /u/Zee2A        1\n",
       "4          /u/MicroSofty88        1\n",
       "3       /u/Lonely-Salt2070        1\n",
       "2          /u/Hyperion1144        1\n",
       "16               /u/wag334        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = df.groupby('author', as_index=False).agg({'title':'count'})\n",
    "authors.columns = ['author', 'entries']\n",
    "authors.sort_values('entries', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we wanted to see which entries had the longest titles, we could create a new column called title_length that contains the number of characters in the title and then sort the data frame by that new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How this underwater buoy captures the Ocean's ...</td>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researchers build a working camera out of atom...</td>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US is increasing pace of hypersonic weapons de...</td>\n",
       "      <td>/u/hopputhas</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tesla opens its EV charging connector design i...</td>\n",
       "      <td>/u/contentPudding28926</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cyber vulnerability in networks used by spacec...</td>\n",
       "      <td>/u/EforieNord</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title                  author  \\\n",
       "15  How this underwater buoy captures the Ocean's ...            /u/Sariel007   \n",
       "1   Researchers build a working camera out of atom...            /u/Sariel007   \n",
       "6   US is increasing pace of hypersonic weapons de...            /u/hopputhas   \n",
       "22  Tesla opens its EV charging connector design i...  /u/contentPudding28926   \n",
       "18  Cyber vulnerability in networks used by spacec...           /u/EforieNord   \n",
       "\n",
       "    title_length  \n",
       "15           148  \n",
       "1            147  \n",
       "6            117  \n",
       "22           106  \n",
       "18            90  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_length'] = df['title'].apply(len)\n",
    "df[['title', 'author', 'title_length']].sort_values('title_length', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a couple of the things you can analyze about the entries using the information we were able to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
